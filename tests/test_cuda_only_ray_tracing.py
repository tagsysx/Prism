#!/usr/bin/env python3
"""
æµ‹è¯•æ¸…ç†åçš„CUDARayTracer
éªŒè¯æ˜¯å¦åªä½¿ç”¨CUDAå®ç°ï¼Œæ²¡æœ‰çº¿ç¨‹æ± æˆ–multiprocessing
"""

import torch
import logging
import sys
import os

# Add the src directory to the path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from prism.ray_tracer_cuda import CUDARayTracer

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')
logger = logging.getLogger(__name__)

def test_cuda_only_ray_tracing():
    """æµ‹è¯•CUDARayTraceræ˜¯å¦åªä½¿ç”¨CUDAå®ç°"""
    
    if not torch.cuda.is_available():
        logger.error("CUDA not available")
        return
    
    logger.info(f"ğŸš€ æµ‹è¯•æ¸…ç†åçš„CUDARayTracer on {torch.cuda.get_device_name()}")
    
    # åˆ›å»ºCUDARayTracer - æ³¨æ„è¿™äº›å‚æ•°ç°åœ¨è¢«å¿½ç•¥
    ray_tracer = CUDARayTracer(
        azimuth_divisions=18,
        elevation_divisions=9,
        max_ray_length=200.0,
        scene_size=200.0,
        device='cuda',
        uniform_samples=64,
        enable_parallel_processing=True,  # è¿™ä¸ªå‚æ•°ç°åœ¨è¢«å¿½ç•¥
        max_workers=8,                   # è¿™ä¸ªå‚æ•°ç°åœ¨è¢«å¿½ç•¥
        use_multiprocessing=True         # è¿™ä¸ªå‚æ•°ç°åœ¨è¢«å¿½ç•¥
    )
    
    logger.info(f"âœ… CUDARayTraceråˆ›å»ºæˆåŠŸ!")
    logger.info(f"   - ray_tracerç±»å‹: {type(ray_tracer).__name__}")
    logger.info(f"   - è®¾å¤‡: {ray_tracer.device}")
    logger.info(f"   - ä½¿ç”¨CUDA: {ray_tracer.use_cuda}")
    logger.info(f"   - å¯ç”¨å¹¶è¡Œå¤„ç†: {ray_tracer.enable_parallel_processing}")
    logger.info(f"   - ä½¿ç”¨å¤šè¿›ç¨‹: {ray_tracer.use_multiprocessing}")
    logger.info(f"   - æœ€å¤§workeræ•°: {ray_tracer.max_workers}")
    
    # éªŒè¯è¿™äº›å‚æ•°è¢«æ­£ç¡®å¿½ç•¥
    if ray_tracer.enable_parallel_processing == False and ray_tracer.use_multiprocessing == False and ray_tracer.max_workers == 0:
        logger.info("ğŸ‰ æˆåŠŸ! æ‰€æœ‰CPUå¹¶è¡Œå‚æ•°éƒ½è¢«æ­£ç¡®å¿½ç•¥!")
    else:
        logger.warning("âš ï¸ æŸäº›CPUå¹¶è¡Œå‚æ•°æ²¡æœ‰è¢«æ­£ç¡®å¿½ç•¥")
    
    # æµ‹è¯•æ•°æ®
    base_station_pos = torch.tensor([0.0, 0.0, 10.0], device='cuda')
    
    # 2ä¸ªUEä½ç½®
    ue_positions = [
        torch.tensor([25.0, 0.0, 1.5], device='cuda'),
        torch.tensor([50.0, 25.0, 1.5], device='cuda'),
    ]
    
    # 8ä¸ªå­è½½æ³¢ per UE
    selected_subcarriers = {}
    for ue_pos in ue_positions:
        ue_key = tuple(ue_pos.tolist())
        selected_subcarriers[ue_key] = list(range(8))
    
    antenna_embeddings = torch.randn(8, 128, device='cuda')
    
    # è®¡ç®—é¢„æœŸå°„çº¿æ•°é‡
    total_directions = ray_tracer.azimuth_divisions * ray_tracer.elevation_divisions
    expected_rays = total_directions * len(ue_positions) * 8
    
    logger.info(f"ğŸ“Š æµ‹è¯•é…ç½®:")
    logger.info(f"   - æ–¹å‘: {total_directions} ({ray_tracer.azimuth_divisions}Ã—{ray_tracer.elevation_divisions})")
    logger.info(f"   - UEä½ç½®: {len(ue_positions)}")
    logger.info(f"   - æ¯UEå­è½½æ³¢: 8")
    logger.info(f"   - é¢„æœŸå°„çº¿: {expected_rays:,}")
    
    # æµ‹è¯•1: ä½¿ç”¨accumulate_signals (åº”è¯¥è°ƒç”¨è¶…ä¼˜åŒ–æ–¹æ³•)
    logger.info(f"\n{'='*60}")
    logger.info("ğŸ” æµ‹è¯•1: accumulate_signalsæ–¹æ³•")
    logger.info(f"{'='*60}")
    
    torch.cuda.empty_cache()
    start_time = time.time()
    
    try:
        # è¿™ä¸ªæ–¹æ³•ç°åœ¨åº”è¯¥è°ƒç”¨æˆ‘ä»¬çš„è¶…ä¼˜åŒ–ç®—æ³•
        results = ray_tracer.accumulate_signals(
            base_station_pos, ue_positions, selected_subcarriers, antenna_embeddings
        )
        
        end_time = time.time()
        total_time = end_time - start_time
        
        actual_results = len(results)
        logger.info(f"âœ… accumulate_signalså®Œæˆ!")
        logger.info(f"   - æ—¶é—´: {total_time:.2f}s ({total_time/60:.2f} åˆ†é’Ÿ)")
        logger.info(f"   - ç»“æœæ•°é‡: {actual_results}")
        
        if total_time < 1:
            logger.info("ğŸ‰ æˆåŠŸ! åœ¨1ç§’å†…å®Œæˆ!")
        elif total_time < 60:
            logger.info("âœ… å¾ˆå¥½! åœ¨1åˆ†é’Ÿå†…å®Œæˆ!")
        else:
            logger.info("âš ï¸ ä»ç„¶éœ€è¦æ›´å¤šä¼˜åŒ–")
            
    except Exception as e:
        logger.error(f"âŒ accumulate_signalså¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æµ‹è¯•2: ç›´æ¥è°ƒç”¨è¶…ä¼˜åŒ–æ–¹æ³•
    logger.info(f"\n{'='*60}")
    logger.info("ğŸ” æµ‹è¯•2: ç›´æ¥è°ƒç”¨è¶…ä¼˜åŒ–æ–¹æ³•")
    logger.info(f"{'='*60}")
    
    torch.cuda.empty_cache()
    start_time = time.time()
    
    try:
        # ç›´æ¥è°ƒç”¨è¶…ä¼˜åŒ–æ–¹æ³•
        direction_vectors = ray_tracer.generate_direction_vectors()
        results = ray_tracer.trace_rays_pytorch_gpu_ultra_optimized(
            base_station_pos, direction_vectors, ue_positions,
            selected_subcarriers, antenna_embeddings
        )
        
        end_time = time.time()
        total_time = end_time - start_time
        
        actual_rays = len(results)
        rays_per_second = actual_rays / total_time
        
        logger.info(f"âœ… ç›´æ¥è¶…ä¼˜åŒ–æ–¹æ³•å®Œæˆ!")
        logger.info(f"   - æ—¶é—´: {total_time:.2f}s ({total_time/60:.2f} åˆ†é’Ÿ)")
        logger.info(f"   - å¤„ç†å°„çº¿: {actual_rays:,}")
        logger.info(f"   - æ€§èƒ½: {rays_per_second:,.0f} å°„çº¿/ç§’")
        
        if total_time < 1:
            logger.info("ğŸ‰ æˆåŠŸ! åœ¨1ç§’å†…å®Œæˆ!")
        elif total_time < 60:
            logger.info("âœ… å¾ˆå¥½! åœ¨1åˆ†é’Ÿå†…å®Œæˆ!")
        else:
            logger.info("âš ï¸ ä»ç„¶éœ€è¦æ›´å¤šä¼˜åŒ–")
            
    except Exception as e:
        logger.error(f"âŒ ç›´æ¥è¶…ä¼˜åŒ–æ–¹æ³•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æµ‹è¯•3: æ£€æŸ¥æ˜¯å¦æœ‰çº¿ç¨‹æ± ç›¸å…³çš„å¯¼å…¥
    logger.info(f"\n{'='*60}")
    logger.info("ğŸ” æµ‹è¯•3: æ£€æŸ¥ä»£ç æ¸…ç†")
    logger.info(f"{'='*60}")
    
    # æ£€æŸ¥æºä»£ç ä¸­æ˜¯å¦è¿˜æœ‰çº¿ç¨‹æ± ç›¸å…³çš„ä»£ç 
    source_file = "src/prism/ray_tracer_cuda.py"
    if os.path.exists(source_file):
        with open(source_file, 'r') as f:
            source_content = f.read()
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰çº¿ç¨‹æ± ç›¸å…³çš„ä»£ç 
        thread_pool_mentions = source_content.count("ThreadPoolExecutor")
        multiprocessing_mentions = source_content.count("multiprocessing")
        max_workers_mentions = source_content.count("max_workers")
        
        logger.info(f"ğŸ“Š ä»£ç æ¸…ç†æ£€æŸ¥:")
        logger.info(f"   - ThreadPoolExecutorå¼•ç”¨: {thread_pool_mentions}")
        logger.info(f"   - multiprocessingå¼•ç”¨: {multiprocessing_mentions}")
        logger.info(f"   - max_workerså¼•ç”¨: {max_workers_mentions}")
        
        if thread_pool_mentions == 0 and multiprocessing_mentions == 0:
            logger.info("ğŸ‰ æˆåŠŸ! æ‰€æœ‰çº¿ç¨‹æ± å’Œå¤šè¿›ç¨‹ä»£ç éƒ½è¢«æ¸…ç†!")
        else:
            logger.warning("âš ï¸ ä»æœ‰çº¿ç¨‹æ± æˆ–å¤šè¿›ç¨‹ç›¸å…³ä»£ç ")
    else:
        logger.warning("âš ï¸ æ— æ³•æ‰¾åˆ°æºä»£ç æ–‡ä»¶è¿›è¡Œæ£€æŸ¥")

if __name__ == "__main__":
    import time
    
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•æ¸…ç†åçš„CUDARayTracer")
    logger.info("=" * 80)
    
    test_cuda_only_ray_tracing()
    
    logger.info("\nğŸ æµ‹è¯•å®Œæˆ!")
    logger.info("=" * 80)
